{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d5f80df",
   "metadata": {},
   "source": [
    "## In this code, I am running a CRFsuite model using folds created by Original paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3b2c4",
   "metadata": {},
   "source": [
    "### Running for all 5 folds for one topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23030a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "import os\n",
    "\n",
    "# Function to load data\n",
    "\n",
    "def load_data(filenames):\n",
    "    X, y = [], []\n",
    "    total_lines_read = 0\n",
    "    total_lines_skipped = 0\n",
    "\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as f:\n",
    "            lines_read = 0\n",
    "            lines_skipped = 0\n",
    "            X_fold, y_fold = [], []\n",
    "            for line in f:\n",
    "                lines_read += 1\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    lines_skipped += 1\n",
    "                    continue\n",
    "                label = parts[0]\n",
    "                features = {feat.split(':')[0]: float(feat.split(':')[1]) for feat in parts[1:]}\n",
    "                X_fold.append([features])\n",
    "                y_fold.append(label)\n",
    "            X.extend(X_fold)\n",
    "            y.extend(y_fold)\n",
    "            \n",
    "            print(f\"File: {filename}\")\n",
    "            print(f\"  Lines read: {lines_read}\")\n",
    "            print(f\"  Lines skipped: {lines_skipped}\")\n",
    "            \n",
    "            total_lines_read += lines_read\n",
    "            total_lines_skipped += lines_skipped\n",
    "\n",
    "    print(\"Total across all folds:\")\n",
    "    print(f\"  Total lines read: {total_lines_read}\")\n",
    "    print(f\"  Total lines skipped: {total_lines_skipped}\")\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47ff385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the fold files\n",
    "\n",
    "# dir_path = './core-tech/crf-tmp-1086/'\n",
    "dir_path = './core-tech/crf-tmp-1439/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbceb832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pass 0\n",
      "training_files ['fold.3', 'fold.4', 'fold.2', 'fold.1']\n",
      "testing_file fold.0\n",
      "File: ./core-tech/crf-tmp-1439/fold.3\n",
      "  Lines read: 51950\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.4\n",
      "  Lines read: 57876\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.2\n",
      "  Lines read: 53269\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.1\n",
      "  Lines read: 46586\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 209681\n",
      "  Total lines skipped: 100\n",
      "File: ./core-tech/crf-tmp-1439/fold.0\n",
      "  Lines read: 52686\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 52686\n",
      "  Total lines skipped: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|█| 209581/209581 [00:18<00:00, 11338.77i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 1021444\n",
      "Seconds required: 6.963\n",
      "\n",
      "Passive Aggressive\n",
      "type: 2\n",
      "c: 0.100000\n",
      "error_sensitive: 1\n",
      "averaging: 1\n",
      "max_iterations: 100\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.60  loss=844.92   feature_norm=0.61\n",
      "Iter 2   time=0.55  loss=585.89   feature_norm=0.81\n",
      "Iter 3   time=0.54  loss=512.78   feature_norm=0.95\n",
      "Iter 4   time=0.52  loss=444.48   feature_norm=1.06\n",
      "Iter 5   time=0.57  loss=427.03   feature_norm=1.15\n",
      "Iter 6   time=0.56  loss=437.47   feature_norm=1.25\n",
      "Iter 7   time=0.53  loss=416.91   feature_norm=1.33\n",
      "Iter 8   time=0.52  loss=363.63   feature_norm=1.40\n",
      "Iter 9   time=0.52  loss=372.71   feature_norm=1.47\n",
      "Iter 10  time=0.52  loss=380.65   feature_norm=1.53\n",
      "Iter 11  time=0.57  loss=358.90   feature_norm=1.59\n",
      "Iter 12  time=0.54  loss=387.73   feature_norm=1.65\n",
      "Iter 13  time=0.53  loss=354.34   feature_norm=1.71\n",
      "Iter 14  time=0.52  loss=367.33   feature_norm=1.76\n",
      "Iter 15  time=0.53  loss=338.47   feature_norm=1.80\n",
      "Iter 16  time=0.52  loss=340.17   feature_norm=1.84\n",
      "Iter 17  time=0.53  loss=324.59   feature_norm=1.89\n",
      "Iter 18  time=0.54  loss=307.12   feature_norm=1.92\n",
      "Iter 19  time=0.52  loss=340.14   feature_norm=1.97\n",
      "Iter 20  time=0.53  loss=345.58   feature_norm=2.01\n",
      "Iter 21  time=0.53  loss=326.20   feature_norm=2.05\n",
      "Iter 22  time=0.53  loss=324.84   feature_norm=2.09\n",
      "Iter 23  time=0.53  loss=339.73   feature_norm=2.13\n",
      "Iter 24  time=0.53  loss=311.14   feature_norm=2.16\n",
      "Iter 25  time=0.55  loss=323.69   feature_norm=2.19\n",
      "Iter 26  time=0.52  loss=294.09   feature_norm=2.22\n",
      "Iter 27  time=0.54  loss=315.93   feature_norm=2.25\n",
      "Iter 28  time=0.53  loss=300.02   feature_norm=2.27\n",
      "Iter 29  time=0.52  loss=291.95   feature_norm=2.30\n",
      "Iter 30  time=0.53  loss=306.78   feature_norm=2.33\n",
      "Iter 31  time=0.52  loss=299.15   feature_norm=2.36\n",
      "Iter 32  time=0.53  loss=331.61   feature_norm=2.39\n",
      "Iter 33  time=0.53  loss=326.60   feature_norm=2.41\n",
      "Iter 34  time=0.53  loss=283.54   feature_norm=2.43\n",
      "Iter 35  time=0.53  loss=277.00   feature_norm=2.46\n",
      "Iter 36  time=0.52  loss=303.93   feature_norm=2.48\n",
      "Iter 37  time=0.52  loss=307.79   feature_norm=2.51\n",
      "Iter 38  time=0.52  loss=298.75   feature_norm=2.54\n",
      "Iter 39  time=0.52  loss=291.14   feature_norm=2.56\n",
      "Iter 40  time=0.52  loss=331.97   feature_norm=2.59\n",
      "Iter 41  time=0.52  loss=320.88   feature_norm=2.62\n",
      "Iter 42  time=0.52  loss=302.15   feature_norm=2.64\n",
      "Iter 43  time=0.52  loss=289.13   feature_norm=2.66\n",
      "Iter 44  time=0.55  loss=300.87   feature_norm=2.67\n",
      "Iter 45  time=0.55  loss=281.54   feature_norm=2.70\n",
      "Iter 46  time=0.52  loss=314.95   feature_norm=2.71\n",
      "Iter 47  time=0.53  loss=284.66   feature_norm=2.73\n",
      "Iter 48  time=0.53  loss=271.71   feature_norm=2.75\n",
      "Iter 49  time=0.53  loss=307.81   feature_norm=2.77\n",
      "Iter 50  time=0.53  loss=291.58   feature_norm=2.79\n",
      "Iter 51  time=0.52  loss=278.19   feature_norm=2.81\n",
      "Iter 52  time=0.52  loss=295.71   feature_norm=2.83\n",
      "Iter 53  time=0.53  loss=292.96   feature_norm=2.85\n",
      "Iter 54  time=0.53  loss=278.73   feature_norm=2.87\n",
      "Iter 55  time=0.52  loss=264.36   feature_norm=2.88\n",
      "Iter 56  time=0.53  loss=291.62   feature_norm=2.91\n",
      "Iter 57  time=0.53  loss=266.09   feature_norm=2.92\n",
      "Iter 58  time=0.52  loss=288.41   feature_norm=2.94\n",
      "Iter 59  time=0.52  loss=281.94   feature_norm=2.96\n",
      "Iter 60  time=0.53  loss=293.08   feature_norm=2.98\n",
      "Iter 61  time=0.52  loss=282.28   feature_norm=2.99\n",
      "Iter 62  time=0.52  loss=282.29   feature_norm=3.01\n",
      "Iter 63  time=0.52  loss=284.35   feature_norm=3.03\n",
      "Iter 64  time=0.60  loss=291.41   feature_norm=3.05\n",
      "Iter 65  time=0.60  loss=272.18   feature_norm=3.06\n",
      "Iter 66  time=0.54  loss=287.39   feature_norm=3.08\n",
      "Iter 67  time=0.54  loss=301.14   feature_norm=3.10\n",
      "Iter 68  time=0.54  loss=296.43   feature_norm=3.11\n",
      "Iter 69  time=0.54  loss=289.78   feature_norm=3.13\n",
      "Iter 70  time=0.54  loss=294.97   feature_norm=3.14\n",
      "Iter 71  time=0.54  loss=278.67   feature_norm=3.16\n",
      "Iter 72  time=0.54  loss=290.17   feature_norm=3.18\n",
      "Iter 73  time=0.54  loss=297.41   feature_norm=3.19\n",
      "Iter 74  time=0.54  loss=257.23   feature_norm=3.21\n",
      "Iter 75  time=0.54  loss=291.84   feature_norm=3.22\n",
      "Iter 76  time=0.54  loss=293.14   feature_norm=3.24\n",
      "Iter 77  time=0.56  loss=291.68   feature_norm=3.25\n",
      "Iter 78  time=0.53  loss=249.19   feature_norm=3.27\n",
      "Iter 79  time=0.53  loss=275.43   feature_norm=3.28\n",
      "Iter 80  time=0.54  loss=279.19   feature_norm=3.30\n",
      "Iter 81  time=0.55  loss=287.84   feature_norm=3.31\n",
      "Iter 82  time=0.57  loss=296.27   feature_norm=3.33\n",
      "Iter 83  time=0.58  loss=275.63   feature_norm=3.34\n",
      "Iter 84  time=0.54  loss=290.17   feature_norm=3.36\n",
      "Iter 85  time=0.54  loss=263.61   feature_norm=3.37\n",
      "Iter 86  time=0.54  loss=286.91   feature_norm=3.39\n",
      "Iter 87  time=0.54  loss=302.92   feature_norm=3.40\n",
      "Iter 88  time=0.54  loss=276.07   feature_norm=3.41\n",
      "Iter 89  time=0.53  loss=284.37   feature_norm=3.43\n",
      "Iter 90  time=0.54  loss=283.14   feature_norm=3.44\n",
      "Iter 91  time=0.54  loss=270.51   feature_norm=3.46\n",
      "Iter 92  time=0.54  loss=267.02   feature_norm=3.47\n",
      "Iter 93  time=0.53  loss=288.86   feature_norm=3.48\n",
      "Iter 94  time=0.54  loss=275.64   feature_norm=3.50\n",
      "Iter 95  time=0.54  loss=279.55   feature_norm=3.51\n",
      "Iter 96  time=0.54  loss=297.94   feature_norm=3.52\n",
      "Iter 97  time=0.53  loss=264.55   feature_norm=3.53\n",
      "Iter 98  time=0.54  loss=283.98   feature_norm=3.55\n",
      "Iter 99  time=0.54  loss=254.57   feature_norm=3.56\n",
      "Iter 100 time=0.55  loss=280.04   feature_norm=3.57\n",
      "Total seconds required for training: 53.577\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 94897 (1021444)\n",
      "Number of active attributes: 78545 (1004026)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.161\n",
      "\n",
      "Running pass 1\n",
      "training_files ['fold.3', 'fold.4', 'fold.2', 'fold.0']\n",
      "testing_file fold.1\n",
      "File: ./core-tech/crf-tmp-1439/fold.3\n",
      "  Lines read: 51950\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.4\n",
      "  Lines read: 57876\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.2\n",
      "  Lines read: 53269\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.0\n",
      "  Lines read: 52686\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 215781\n",
      "  Total lines skipped: 100\n",
      "File: ./core-tech/crf-tmp-1439/fold.1\n",
      "  Lines read: 46586\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 46586\n",
      "  Total lines skipped: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|█| 215681/215681 [00:22<00:00, 9625.67it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 1046651\n",
      "Seconds required: 7.171\n",
      "\n",
      "Passive Aggressive\n",
      "type: 2\n",
      "c: 0.100000\n",
      "error_sensitive: 1\n",
      "averaging: 1\n",
      "max_iterations: 100\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.60  loss=839.55   feature_norm=0.61\n",
      "Iter 2   time=0.56  loss=607.68   feature_norm=0.80\n",
      "Iter 3   time=0.56  loss=535.41   feature_norm=0.94\n",
      "Iter 4   time=0.56  loss=476.15   feature_norm=1.05\n",
      "Iter 5   time=0.56  loss=414.48   feature_norm=1.15\n",
      "Iter 6   time=0.56  loss=408.03   feature_norm=1.23\n",
      "Iter 7   time=0.57  loss=396.53   feature_norm=1.30\n",
      "Iter 8   time=0.57  loss=404.94   feature_norm=1.38\n",
      "Iter 9   time=0.58  loss=379.43   feature_norm=1.45\n",
      "Iter 10  time=0.58  loss=394.46   feature_norm=1.51\n",
      "Iter 11  time=0.58  loss=356.05   feature_norm=1.56\n",
      "Iter 12  time=0.57  loss=368.56   feature_norm=1.62\n",
      "Iter 13  time=0.56  loss=371.28   feature_norm=1.67\n",
      "Iter 14  time=0.55  loss=316.59   feature_norm=1.72\n",
      "Iter 15  time=0.56  loss=361.34   feature_norm=1.77\n",
      "Iter 16  time=0.56  loss=328.50   feature_norm=1.82\n",
      "Iter 17  time=0.56  loss=326.43   feature_norm=1.86\n",
      "Iter 18  time=0.56  loss=317.88   feature_norm=1.90\n",
      "Iter 19  time=0.56  loss=324.00   feature_norm=1.94\n",
      "Iter 20  time=0.56  loss=339.38   feature_norm=1.97\n",
      "Iter 21  time=0.55  loss=295.83   feature_norm=2.01\n",
      "Iter 22  time=0.56  loss=284.62   feature_norm=2.04\n",
      "Iter 23  time=0.55  loss=323.85   feature_norm=2.07\n",
      "Iter 24  time=0.55  loss=334.39   feature_norm=2.11\n",
      "Iter 25  time=0.55  loss=306.24   feature_norm=2.14\n",
      "Iter 26  time=0.56  loss=305.85   feature_norm=2.17\n",
      "Iter 27  time=0.56  loss=303.94   feature_norm=2.20\n",
      "Iter 28  time=0.55  loss=322.67   feature_norm=2.23\n",
      "Iter 29  time=0.56  loss=304.76   feature_norm=2.26\n",
      "Iter 30  time=0.56  loss=294.65   feature_norm=2.29\n",
      "Iter 31  time=0.55  loss=306.85   feature_norm=2.32\n",
      "Iter 32  time=0.55  loss=327.22   feature_norm=2.34\n",
      "Iter 33  time=0.55  loss=297.03   feature_norm=2.37\n",
      "Iter 34  time=0.55  loss=295.27   feature_norm=2.40\n",
      "Iter 35  time=0.56  loss=306.70   feature_norm=2.43\n",
      "Iter 36  time=0.55  loss=287.21   feature_norm=2.44\n",
      "Iter 37  time=0.56  loss=289.61   feature_norm=2.47\n",
      "Iter 38  time=0.55  loss=314.46   feature_norm=2.50\n",
      "Iter 39  time=0.55  loss=291.97   feature_norm=2.52\n",
      "Iter 40  time=0.55  loss=304.09   feature_norm=2.55\n",
      "Iter 41  time=0.56  loss=304.24   feature_norm=2.58\n",
      "Iter 42  time=0.56  loss=297.38   feature_norm=2.60\n",
      "Iter 43  time=0.56  loss=292.30   feature_norm=2.63\n",
      "Iter 44  time=0.55  loss=305.99   feature_norm=2.65\n",
      "Iter 45  time=0.55  loss=296.14   feature_norm=2.67\n",
      "Iter 46  time=0.55  loss=303.73   feature_norm=2.69\n",
      "Iter 47  time=0.55  loss=292.88   feature_norm=2.71\n",
      "Iter 48  time=0.55  loss=290.53   feature_norm=2.74\n",
      "Iter 49  time=0.55  loss=292.26   feature_norm=2.76\n",
      "Iter 50  time=0.55  loss=282.57   feature_norm=2.78\n",
      "Iter 51  time=0.55  loss=274.13   feature_norm=2.80\n",
      "Iter 52  time=0.55  loss=292.70   feature_norm=2.82\n",
      "Iter 53  time=0.56  loss=286.00   feature_norm=2.84\n",
      "Iter 54  time=0.56  loss=280.12   feature_norm=2.86\n",
      "Iter 55  time=0.55  loss=309.23   feature_norm=2.88\n",
      "Iter 56  time=0.56  loss=282.58   feature_norm=2.90\n",
      "Iter 57  time=0.55  loss=301.34   feature_norm=2.92\n",
      "Iter 58  time=0.55  loss=269.66   feature_norm=2.93\n",
      "Iter 59  time=0.55  loss=289.17   feature_norm=2.95\n",
      "Iter 60  time=0.55  loss=278.30   feature_norm=2.97\n",
      "Iter 61  time=0.58  loss=282.48   feature_norm=2.99\n",
      "Iter 62  time=0.62  loss=275.52   feature_norm=3.00\n",
      "Iter 63  time=0.64  loss=271.52   feature_norm=3.02\n",
      "Iter 64  time=0.63  loss=265.43   feature_norm=3.04\n",
      "Iter 65  time=0.64  loss=279.89   feature_norm=3.05\n",
      "Iter 66  time=0.69  loss=287.76   feature_norm=3.08\n",
      "Iter 67  time=0.64  loss=283.40   feature_norm=3.09\n",
      "Iter 68  time=0.65  loss=277.21   feature_norm=3.11\n",
      "Iter 69  time=0.64  loss=283.38   feature_norm=3.12\n",
      "Iter 70  time=0.64  loss=284.11   feature_norm=3.14\n",
      "Iter 71  time=0.64  loss=267.33   feature_norm=3.16\n",
      "Iter 72  time=0.63  loss=295.41   feature_norm=3.17\n",
      "Iter 73  time=0.63  loss=265.72   feature_norm=3.18\n",
      "Iter 74  time=0.63  loss=282.85   feature_norm=3.20\n",
      "Iter 75  time=0.62  loss=270.44   feature_norm=3.22\n",
      "Iter 76  time=0.63  loss=274.21   feature_norm=3.24\n",
      "Iter 77  time=0.64  loss=271.31   feature_norm=3.25\n",
      "Iter 78  time=0.63  loss=267.43   feature_norm=3.27\n",
      "Iter 79  time=0.63  loss=266.49   feature_norm=3.28\n",
      "Iter 80  time=0.64  loss=281.21   feature_norm=3.30\n",
      "Iter 81  time=0.64  loss=283.72   feature_norm=3.31\n",
      "Iter 82  time=0.64  loss=298.62   feature_norm=3.33\n",
      "Iter 83  time=0.64  loss=276.02   feature_norm=3.34\n",
      "Iter 84  time=0.63  loss=257.05   feature_norm=3.35\n",
      "Iter 85  time=0.65  loss=273.48   feature_norm=3.36\n",
      "Iter 86  time=0.65  loss=267.79   feature_norm=3.38\n",
      "Iter 87  time=0.64  loss=266.74   feature_norm=3.39\n",
      "Iter 88  time=0.64  loss=302.36   feature_norm=3.41\n",
      "Iter 89  time=0.64  loss=271.81   feature_norm=3.42\n",
      "Iter 90  time=0.64  loss=272.88   feature_norm=3.43\n",
      "Iter 91  time=0.64  loss=288.31   feature_norm=3.45\n",
      "Iter 92  time=0.64  loss=274.75   feature_norm=3.46\n",
      "Iter 93  time=0.65  loss=269.93   feature_norm=3.47\n",
      "Iter 94  time=0.63  loss=275.96   feature_norm=3.48\n",
      "Iter 95  time=0.65  loss=273.01   feature_norm=3.50\n",
      "Iter 96  time=0.64  loss=270.43   feature_norm=3.51\n",
      "Iter 97  time=0.64  loss=271.20   feature_norm=3.52\n",
      "Iter 98  time=0.64  loss=271.26   feature_norm=3.54\n",
      "Iter 99  time=0.64  loss=284.90   feature_norm=3.55\n",
      "Iter 100 time=0.63  loss=276.63   feature_norm=3.56\n",
      "Total seconds required for training: 58.940\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 94866 (1046651)\n",
      "Number of active attributes: 78539 (1029107)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.167\n",
      "\n",
      "Running pass 2\n",
      "training_files ['fold.3', 'fold.4', 'fold.0', 'fold.1']\n",
      "testing_file fold.2\n",
      "File: ./core-tech/crf-tmp-1439/fold.3\n",
      "  Lines read: 51950\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.4\n",
      "  Lines read: 57876\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.0\n",
      "  Lines read: 52686\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.1\n",
      "  Lines read: 46586\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 209098\n",
      "  Total lines skipped: 100\n",
      "File: ./core-tech/crf-tmp-1439/fold.2\n",
      "  Lines read: 53269\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 53269\n",
      "  Total lines skipped: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|█| 208998/208998 [00:26<00:00, 7911.09it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 1037365\n",
      "Seconds required: 8.045\n",
      "\n",
      "Passive Aggressive\n",
      "type: 2\n",
      "c: 0.100000\n",
      "error_sensitive: 1\n",
      "averaging: 1\n",
      "max_iterations: 100\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.72  loss=849.78   feature_norm=0.61\n",
      "Iter 2   time=0.72  loss=592.36   feature_norm=0.80\n",
      "Iter 3   time=0.71  loss=529.79   feature_norm=0.94\n",
      "Iter 4   time=0.71  loss=482.66   feature_norm=1.05\n",
      "Iter 5   time=0.72  loss=458.97   feature_norm=1.15\n",
      "Iter 6   time=0.71  loss=430.38   feature_norm=1.24\n",
      "Iter 7   time=0.72  loss=413.56   feature_norm=1.31\n",
      "Iter 8   time=0.71  loss=397.36   feature_norm=1.38\n",
      "Iter 9   time=0.72  loss=348.78   feature_norm=1.44\n",
      "Iter 10  time=0.71  loss=370.98   feature_norm=1.51\n",
      "Iter 11  time=0.72  loss=387.36   feature_norm=1.57\n",
      "Iter 12  time=0.72  loss=384.18   feature_norm=1.63\n",
      "Iter 13  time=0.71  loss=382.71   feature_norm=1.68\n",
      "Iter 14  time=0.71  loss=336.02   feature_norm=1.73\n",
      "Iter 15  time=0.71  loss=365.50   feature_norm=1.78\n",
      "Iter 16  time=0.71  loss=347.72   feature_norm=1.82\n",
      "Iter 17  time=0.71  loss=349.90   feature_norm=1.87\n",
      "Iter 18  time=0.71  loss=356.78   feature_norm=1.91\n",
      "Iter 19  time=0.71  loss=347.36   feature_norm=1.95\n",
      "Iter 20  time=0.71  loss=350.86   feature_norm=1.99\n",
      "Iter 21  time=0.71  loss=342.25   feature_norm=2.03\n",
      "Iter 22  time=0.71  loss=335.47   feature_norm=2.07\n",
      "Iter 23  time=0.71  loss=331.82   feature_norm=2.11\n",
      "Iter 24  time=0.71  loss=343.28   feature_norm=2.14\n",
      "Iter 25  time=0.71  loss=348.64   feature_norm=2.18\n",
      "Iter 26  time=0.72  loss=330.71   feature_norm=2.21\n",
      "Iter 27  time=0.71  loss=354.15   feature_norm=2.24\n",
      "Iter 28  time=0.71  loss=320.87   feature_norm=2.27\n",
      "Iter 29  time=0.71  loss=330.34   feature_norm=2.30\n",
      "Iter 30  time=0.71  loss=338.87   feature_norm=2.33\n",
      "Iter 31  time=0.72  loss=326.47   feature_norm=2.36\n",
      "Iter 32  time=0.71  loss=318.78   feature_norm=2.39\n",
      "Iter 33  time=0.72  loss=338.04   feature_norm=2.42\n",
      "Iter 34  time=0.72  loss=301.60   feature_norm=2.44\n",
      "Iter 35  time=0.72  loss=325.41   feature_norm=2.47\n",
      "Iter 36  time=0.72  loss=318.42   feature_norm=2.50\n",
      "Iter 37  time=0.72  loss=305.37   feature_norm=2.52\n",
      "Iter 38  time=0.72  loss=303.98   feature_norm=2.55\n",
      "Iter 39  time=0.72  loss=293.94   feature_norm=2.58\n",
      "Iter 40  time=0.71  loss=334.55   feature_norm=2.60\n",
      "Iter 41  time=0.72  loss=289.11   feature_norm=2.62\n",
      "Iter 42  time=0.73  loss=313.46   feature_norm=2.65\n",
      "Iter 43  time=0.72  loss=337.48   feature_norm=2.67\n",
      "Iter 44  time=0.71  loss=314.40   feature_norm=2.69\n",
      "Iter 45  time=0.73  loss=309.66   feature_norm=2.71\n",
      "Iter 46  time=0.72  loss=314.83   feature_norm=2.74\n",
      "Iter 47  time=0.71  loss=307.74   feature_norm=2.76\n",
      "Iter 48  time=0.72  loss=279.36   feature_norm=2.78\n",
      "Iter 49  time=0.71  loss=296.46   feature_norm=2.80\n",
      "Iter 50  time=0.71  loss=311.70   feature_norm=2.82\n",
      "Iter 51  time=0.71  loss=315.14   feature_norm=2.84\n",
      "Iter 52  time=0.71  loss=303.56   feature_norm=2.86\n",
      "Iter 53  time=0.71  loss=295.87   feature_norm=2.88\n",
      "Iter 54  time=0.72  loss=297.25   feature_norm=2.90\n",
      "Iter 55  time=0.72  loss=295.30   feature_norm=2.92\n",
      "Iter 56  time=0.71  loss=293.48   feature_norm=2.94\n",
      "Iter 57  time=0.72  loss=284.56   feature_norm=2.95\n",
      "Iter 58  time=0.71  loss=303.36   feature_norm=2.97\n",
      "Iter 59  time=0.71  loss=304.30   feature_norm=2.99\n",
      "Iter 60  time=0.71  loss=298.29   feature_norm=3.01\n",
      "Iter 61  time=0.71  loss=292.44   feature_norm=3.03\n",
      "Iter 62  time=0.72  loss=315.40   feature_norm=3.05\n",
      "Iter 63  time=0.73  loss=290.01   feature_norm=3.07\n",
      "Iter 64  time=0.72  loss=300.81   feature_norm=3.09\n",
      "Iter 65  time=0.72  loss=304.94   feature_norm=3.11\n",
      "Iter 66  time=0.71  loss=296.32   feature_norm=3.12\n",
      "Iter 67  time=0.71  loss=305.17   feature_norm=3.14\n",
      "Iter 68  time=0.71  loss=299.48   feature_norm=3.16\n",
      "Iter 69  time=0.71  loss=287.25   feature_norm=3.18\n",
      "Iter 70  time=0.71  loss=302.34   feature_norm=3.20\n",
      "Iter 71  time=0.71  loss=280.72   feature_norm=3.22\n",
      "Iter 72  time=0.71  loss=315.21   feature_norm=3.23\n",
      "Iter 73  time=0.71  loss=289.73   feature_norm=3.25\n",
      "Iter 74  time=0.73  loss=315.68   feature_norm=3.27\n",
      "Iter 75  time=0.72  loss=300.72   feature_norm=3.28\n",
      "Iter 76  time=0.72  loss=278.80   feature_norm=3.30\n",
      "Iter 77  time=0.71  loss=306.78   feature_norm=3.32\n",
      "Iter 78  time=0.71  loss=287.92   feature_norm=3.33\n",
      "Iter 79  time=0.71  loss=299.23   feature_norm=3.35\n",
      "Iter 80  time=0.72  loss=283.70   feature_norm=3.36\n",
      "Iter 81  time=0.71  loss=291.18   feature_norm=3.38\n",
      "Iter 82  time=0.71  loss=328.47   feature_norm=3.39\n",
      "Iter 83  time=0.71  loss=278.20   feature_norm=3.41\n",
      "Iter 84  time=0.71  loss=293.96   feature_norm=3.42\n",
      "Iter 85  time=0.71  loss=281.83   feature_norm=3.44\n",
      "Iter 86  time=0.71  loss=287.91   feature_norm=3.45\n",
      "Iter 87  time=0.71  loss=298.06   feature_norm=3.47\n",
      "Iter 88  time=0.72  loss=285.38   feature_norm=3.48\n",
      "Iter 89  time=0.72  loss=290.21   feature_norm=3.49\n",
      "Iter 90  time=0.75  loss=295.79   feature_norm=3.51\n",
      "Iter 91  time=0.72  loss=268.81   feature_norm=3.52\n",
      "Iter 92  time=0.73  loss=304.12   feature_norm=3.54\n",
      "Iter 93  time=0.72  loss=277.64   feature_norm=3.55\n",
      "Iter 94  time=0.73  loss=292.62   feature_norm=3.57\n",
      "Iter 95  time=0.72  loss=280.16   feature_norm=3.58\n",
      "Iter 96  time=0.71  loss=292.52   feature_norm=3.59\n",
      "Iter 97  time=0.72  loss=296.17   feature_norm=3.61\n",
      "Iter 98  time=0.72  loss=290.76   feature_norm=3.62\n",
      "Iter 99  time=0.72  loss=278.58   feature_norm=3.63\n",
      "Iter 100 time=0.72  loss=293.10   feature_norm=3.65\n",
      "Total seconds required for training: 71.614\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 95640 (1037365)\n",
      "Number of active attributes: 79819 (1020694)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.169\n",
      "\n",
      "Running pass 3\n",
      "training_files ['fold.4', 'fold.2', 'fold.0', 'fold.1']\n",
      "testing_file fold.3\n",
      "File: ./core-tech/crf-tmp-1439/fold.4\n",
      "  Lines read: 57876\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.2\n",
      "  Lines read: 53269\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.0\n",
      "  Lines read: 52686\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.1\n",
      "  Lines read: 46586\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 210417\n",
      "  Total lines skipped: 100\n",
      "File: ./core-tech/crf-tmp-1439/fold.3\n",
      "  Lines read: 51950\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 51950\n",
      "  Total lines skipped: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|█| 210317/210317 [00:24<00:00, 8436.06it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 1045136\n",
      "Seconds required: 7.799\n",
      "\n",
      "Passive Aggressive\n",
      "type: 2\n",
      "c: 0.100000\n",
      "error_sensitive: 1\n",
      "averaging: 1\n",
      "max_iterations: 100\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.76  loss=843.31   feature_norm=0.59\n",
      "Iter 2   time=0.75  loss=547.79   feature_norm=0.77\n",
      "Iter 3   time=0.75  loss=483.35   feature_norm=0.91\n",
      "Iter 4   time=0.76  loss=462.92   feature_norm=1.02\n",
      "Iter 5   time=0.76  loss=450.17   feature_norm=1.12\n",
      "Iter 6   time=0.75  loss=432.86   feature_norm=1.22\n",
      "Iter 7   time=0.75  loss=377.68   feature_norm=1.29\n",
      "Iter 8   time=0.76  loss=398.86   feature_norm=1.36\n",
      "Iter 9   time=0.75  loss=350.97   feature_norm=1.41\n",
      "Iter 10  time=0.76  loss=331.66   feature_norm=1.46\n",
      "Iter 11  time=0.75  loss=365.07   feature_norm=1.53\n",
      "Iter 12  time=0.76  loss=332.38   feature_norm=1.58\n",
      "Iter 13  time=0.78  loss=331.80   feature_norm=1.62\n",
      "Iter 14  time=0.75  loss=328.34   feature_norm=1.67\n",
      "Iter 15  time=0.74  loss=325.50   feature_norm=1.71\n",
      "Iter 16  time=0.75  loss=348.87   feature_norm=1.76\n",
      "Iter 17  time=0.75  loss=305.14   feature_norm=1.80\n",
      "Iter 18  time=0.75  loss=334.11   feature_norm=1.85\n",
      "Iter 19  time=0.75  loss=331.49   feature_norm=1.89\n",
      "Iter 20  time=0.74  loss=306.29   feature_norm=1.92\n",
      "Iter 21  time=0.75  loss=319.04   feature_norm=1.96\n",
      "Iter 22  time=0.75  loss=299.89   feature_norm=2.00\n",
      "Iter 23  time=0.75  loss=315.32   feature_norm=2.04\n",
      "Iter 24  time=0.75  loss=293.58   feature_norm=2.07\n",
      "Iter 25  time=0.76  loss=309.25   feature_norm=2.10\n",
      "Iter 26  time=0.76  loss=311.13   feature_norm=2.13\n",
      "Iter 27  time=0.75  loss=299.66   feature_norm=2.16\n",
      "Iter 28  time=0.75  loss=305.66   feature_norm=2.19\n",
      "Iter 29  time=0.75  loss=300.37   feature_norm=2.22\n",
      "Iter 30  time=0.75  loss=312.73   feature_norm=2.25\n",
      "Iter 31  time=0.75  loss=266.82   feature_norm=2.28\n",
      "Iter 32  time=0.75  loss=271.55   feature_norm=2.30\n",
      "Iter 33  time=0.75  loss=314.81   feature_norm=2.33\n",
      "Iter 34  time=0.74  loss=286.17   feature_norm=2.35\n",
      "Iter 35  time=0.75  loss=284.91   feature_norm=2.38\n",
      "Iter 36  time=0.74  loss=278.47   feature_norm=2.41\n",
      "Iter 37  time=0.75  loss=300.17   feature_norm=2.43\n",
      "Iter 38  time=0.75  loss=287.84   feature_norm=2.46\n",
      "Iter 39  time=0.75  loss=278.01   feature_norm=2.48\n",
      "Iter 40  time=0.75  loss=272.88   feature_norm=2.51\n",
      "Iter 41  time=0.74  loss=277.07   feature_norm=2.53\n",
      "Iter 42  time=0.76  loss=277.63   feature_norm=2.55\n",
      "Iter 43  time=0.75  loss=281.43   feature_norm=2.57\n",
      "Iter 44  time=0.75  loss=260.03   feature_norm=2.59\n",
      "Iter 45  time=0.75  loss=307.76   feature_norm=2.62\n",
      "Iter 46  time=0.75  loss=282.35   feature_norm=2.64\n",
      "Iter 47  time=0.75  loss=258.34   feature_norm=2.66\n",
      "Iter 48  time=0.75  loss=271.46   feature_norm=2.68\n",
      "Iter 49  time=0.76  loss=280.14   feature_norm=2.70\n",
      "Iter 50  time=0.75  loss=271.76   feature_norm=2.72\n",
      "Iter 51  time=0.75  loss=285.87   feature_norm=2.74\n",
      "Iter 52  time=0.75  loss=273.23   feature_norm=2.77\n",
      "Iter 53  time=0.75  loss=285.34   feature_norm=2.79\n",
      "Iter 54  time=0.75  loss=276.19   feature_norm=2.81\n",
      "Iter 55  time=0.76  loss=286.59   feature_norm=2.82\n",
      "Iter 56  time=0.75  loss=276.23   feature_norm=2.85\n",
      "Iter 57  time=0.75  loss=279.05   feature_norm=2.87\n",
      "Iter 58  time=0.76  loss=263.19   feature_norm=2.89\n",
      "Iter 59  time=0.79  loss=270.81   feature_norm=2.91\n",
      "Iter 60  time=0.75  loss=275.84   feature_norm=2.92\n",
      "Iter 61  time=0.76  loss=272.40   feature_norm=2.94\n",
      "Iter 62  time=0.76  loss=284.44   feature_norm=2.96\n",
      "Iter 63  time=0.75  loss=285.63   feature_norm=2.98\n",
      "Iter 64  time=0.76  loss=264.04   feature_norm=3.00\n",
      "Iter 65  time=0.76  loss=271.34   feature_norm=3.02\n",
      "Iter 66  time=0.76  loss=271.50   feature_norm=3.03\n",
      "Iter 67  time=0.75  loss=250.02   feature_norm=3.05\n",
      "Iter 68  time=0.79  loss=297.18   feature_norm=3.07\n",
      "Iter 69  time=0.76  loss=265.08   feature_norm=3.09\n",
      "Iter 70  time=0.76  loss=266.54   feature_norm=3.10\n",
      "Iter 71  time=0.75  loss=275.55   feature_norm=3.12\n",
      "Iter 72  time=0.76  loss=273.11   feature_norm=3.14\n",
      "Iter 73  time=0.75  loss=250.16   feature_norm=3.15\n",
      "Iter 74  time=0.76  loss=273.98   feature_norm=3.17\n",
      "Iter 75  time=0.76  loss=247.88   feature_norm=3.19\n",
      "Iter 76  time=0.75  loss=267.64   feature_norm=3.20\n",
      "Iter 77  time=0.75  loss=259.65   feature_norm=3.22\n",
      "Iter 78  time=0.76  loss=282.03   feature_norm=3.23\n",
      "Iter 79  time=0.76  loss=269.83   feature_norm=3.25\n",
      "Iter 80  time=0.76  loss=241.48   feature_norm=3.26\n",
      "Iter 81  time=0.75  loss=265.65   feature_norm=3.28\n",
      "Iter 82  time=0.76  loss=265.95   feature_norm=3.29\n",
      "Iter 83  time=0.76  loss=262.43   feature_norm=3.31\n",
      "Iter 84  time=0.75  loss=253.65   feature_norm=3.32\n",
      "Iter 85  time=0.75  loss=272.80   feature_norm=3.33\n",
      "Iter 86  time=0.75  loss=254.18   feature_norm=3.35\n",
      "Iter 87  time=0.77  loss=249.96   feature_norm=3.37\n",
      "Iter 88  time=0.76  loss=255.38   feature_norm=3.38\n",
      "Iter 89  time=0.75  loss=263.71   feature_norm=3.39\n",
      "Iter 90  time=0.76  loss=269.50   feature_norm=3.41\n",
      "Iter 91  time=0.75  loss=243.23   feature_norm=3.42\n",
      "Iter 92  time=0.76  loss=243.55   feature_norm=3.43\n",
      "Iter 93  time=0.76  loss=253.01   feature_norm=3.44\n",
      "Iter 94  time=0.76  loss=256.87   feature_norm=3.45\n",
      "Iter 95  time=0.76  loss=261.36   feature_norm=3.47\n",
      "Iter 96  time=0.76  loss=261.72   feature_norm=3.48\n",
      "Iter 97  time=0.76  loss=257.58   feature_norm=3.49\n",
      "Iter 98  time=0.78  loss=255.80   feature_norm=3.51\n",
      "Iter 99  time=0.76  loss=267.04   feature_norm=3.52\n",
      "Iter 100 time=0.76  loss=246.55   feature_norm=3.53\n",
      "Total seconds required for training: 75.451\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 96145 (1045136)\n",
      "Number of active attributes: 80056 (1028189)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.173\n",
      "\n",
      "Running pass 4\n",
      "training_files ['fold.3', 'fold.2', 'fold.0', 'fold.1']\n",
      "testing_file fold.4\n",
      "File: ./core-tech/crf-tmp-1439/fold.3\n",
      "  Lines read: 51950\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.2\n",
      "  Lines read: 53269\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.0\n",
      "  Lines read: 52686\n",
      "  Lines skipped: 25\n",
      "File: ./core-tech/crf-tmp-1439/fold.1\n",
      "  Lines read: 46586\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 204491\n",
      "  Total lines skipped: 100\n",
      "File: ./core-tech/crf-tmp-1439/fold.4\n",
      "  Lines read: 57876\n",
      "  Lines skipped: 25\n",
      "Total across all folds:\n",
      "  Total lines read: 57876\n",
      "  Total lines skipped: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|█| 204391/204391 [00:25<00:00, 7974.14it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 976543\n",
      "Seconds required: 7.144\n",
      "\n",
      "Passive Aggressive\n",
      "type: 2\n",
      "c: 0.100000\n",
      "error_sensitive: 1\n",
      "averaging: 1\n",
      "max_iterations: 100\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.58  loss=782.47   feature_norm=0.59\n",
      "Iter 2   time=0.57  loss=533.14   feature_norm=0.78\n",
      "Iter 3   time=0.56  loss=454.03   feature_norm=0.90\n",
      "Iter 4   time=0.56  loss=454.05   feature_norm=1.02\n",
      "Iter 5   time=0.56  loss=415.94   feature_norm=1.11\n",
      "Iter 6   time=0.56  loss=378.14   feature_norm=1.19\n",
      "Iter 7   time=0.56  loss=390.55   feature_norm=1.26\n",
      "Iter 8   time=0.56  loss=384.56   feature_norm=1.33\n",
      "Iter 9   time=0.56  loss=358.54   feature_norm=1.40\n",
      "Iter 10  time=0.56  loss=350.94   feature_norm=1.46\n",
      "Iter 11  time=0.56  loss=339.81   feature_norm=1.51\n",
      "Iter 12  time=0.56  loss=333.71   feature_norm=1.56\n",
      "Iter 13  time=0.57  loss=317.07   feature_norm=1.61\n",
      "Iter 14  time=0.57  loss=345.43   feature_norm=1.67\n",
      "Iter 15  time=0.56  loss=325.32   feature_norm=1.71\n",
      "Iter 16  time=0.56  loss=348.97   feature_norm=1.76\n",
      "Iter 17  time=0.56  loss=298.72   feature_norm=1.81\n",
      "Iter 18  time=0.56  loss=317.54   feature_norm=1.84\n",
      "Iter 19  time=0.56  loss=325.84   feature_norm=1.88\n",
      "Iter 20  time=0.56  loss=309.81   feature_norm=1.92\n",
      "Iter 21  time=0.56  loss=301.03   feature_norm=1.95\n",
      "Iter 22  time=0.56  loss=328.92   feature_norm=1.98\n",
      "Iter 23  time=0.56  loss=316.34   feature_norm=2.02\n",
      "Iter 24  time=0.56  loss=294.91   feature_norm=2.05\n",
      "Iter 25  time=0.56  loss=318.48   feature_norm=2.08\n",
      "Iter 26  time=0.56  loss=306.99   feature_norm=2.11\n",
      "Iter 27  time=0.57  loss=313.28   feature_norm=2.13\n",
      "Iter 28  time=0.56  loss=298.50   feature_norm=2.16\n",
      "Iter 29  time=0.56  loss=304.44   feature_norm=2.19\n",
      "Iter 30  time=0.56  loss=296.10   feature_norm=2.22\n",
      "Iter 31  time=0.56  loss=333.13   feature_norm=2.24\n",
      "Iter 32  time=0.57  loss=308.38   feature_norm=2.27\n",
      "Iter 33  time=0.56  loss=289.87   feature_norm=2.29\n",
      "Iter 34  time=0.56  loss=302.14   feature_norm=2.31\n",
      "Iter 35  time=0.56  loss=293.91   feature_norm=2.34\n",
      "Iter 36  time=0.56  loss=299.88   feature_norm=2.36\n",
      "Iter 37  time=0.56  loss=297.86   feature_norm=2.39\n",
      "Iter 38  time=0.56  loss=290.99   feature_norm=2.41\n",
      "Iter 39  time=0.56  loss=287.50   feature_norm=2.43\n",
      "Iter 40  time=0.56  loss=316.51   feature_norm=2.45\n",
      "Iter 41  time=0.55  loss=298.46   feature_norm=2.47\n",
      "Iter 42  time=0.57  loss=284.75   feature_norm=2.49\n",
      "Iter 43  time=0.56  loss=308.67   feature_norm=2.51\n",
      "Iter 44  time=0.56  loss=291.53   feature_norm=2.53\n",
      "Iter 45  time=0.56  loss=286.56   feature_norm=2.55\n",
      "Iter 46  time=0.56  loss=292.71   feature_norm=2.57\n",
      "Iter 47  time=0.56  loss=287.33   feature_norm=2.59\n",
      "Iter 48  time=0.56  loss=296.73   feature_norm=2.61\n",
      "Iter 49  time=0.57  loss=294.96   feature_norm=2.63\n",
      "Iter 50  time=0.56  loss=290.56   feature_norm=2.64\n",
      "Iter 51  time=0.56  loss=289.30   feature_norm=2.67\n",
      "Iter 52  time=0.57  loss=278.27   feature_norm=2.68\n",
      "Iter 53  time=0.57  loss=284.32   feature_norm=2.70\n",
      "Iter 54  time=0.56  loss=297.82   feature_norm=2.72\n",
      "Iter 55  time=0.63  loss=279.94   feature_norm=2.73\n",
      "Iter 56  time=0.67  loss=295.33   feature_norm=2.75\n",
      "Iter 57  time=0.66  loss=278.55   feature_norm=2.77\n",
      "Iter 58  time=0.67  loss=283.19   feature_norm=2.79\n",
      "Iter 59  time=0.68  loss=286.77   feature_norm=2.80\n",
      "Iter 60  time=0.67  loss=287.64   feature_norm=2.82\n",
      "Iter 61  time=0.66  loss=276.79   feature_norm=2.84\n",
      "Iter 62  time=0.67  loss=285.88   feature_norm=2.85\n",
      "Iter 63  time=0.67  loss=276.34   feature_norm=2.87\n",
      "Iter 64  time=0.67  loss=281.81   feature_norm=2.88\n",
      "Iter 65  time=0.67  loss=287.52   feature_norm=2.89\n",
      "Iter 66  time=0.67  loss=288.40   feature_norm=2.91\n",
      "Iter 67  time=0.66  loss=289.28   feature_norm=2.92\n",
      "Iter 68  time=0.66  loss=284.46   feature_norm=2.94\n",
      "Iter 69  time=0.67  loss=286.16   feature_norm=2.95\n",
      "Iter 70  time=0.66  loss=297.25   feature_norm=2.97\n",
      "Iter 71  time=0.66  loss=276.12   feature_norm=2.98\n",
      "Iter 72  time=0.67  loss=269.23   feature_norm=2.99\n",
      "Iter 73  time=0.66  loss=278.57   feature_norm=3.01\n",
      "Iter 74  time=0.67  loss=279.67   feature_norm=3.02\n",
      "Iter 75  time=0.67  loss=270.05   feature_norm=3.03\n",
      "Iter 76  time=0.67  loss=264.07   feature_norm=3.05\n",
      "Iter 77  time=0.66  loss=270.18   feature_norm=3.07\n",
      "Iter 78  time=0.67  loss=277.32   feature_norm=3.08\n",
      "Iter 79  time=0.67  loss=267.80   feature_norm=3.09\n",
      "Iter 80  time=0.66  loss=273.13   feature_norm=3.10\n",
      "Iter 81  time=0.68  loss=271.38   feature_norm=3.11\n",
      "Iter 82  time=0.68  loss=291.11   feature_norm=3.13\n",
      "Iter 83  time=0.67  loss=270.00   feature_norm=3.14\n",
      "Iter 84  time=0.68  loss=280.80   feature_norm=3.15\n",
      "Iter 85  time=0.68  loss=290.86   feature_norm=3.17\n",
      "Iter 86  time=0.68  loss=277.81   feature_norm=3.18\n",
      "Iter 87  time=0.68  loss=274.02   feature_norm=3.19\n",
      "Iter 88  time=0.68  loss=275.54   feature_norm=3.21\n",
      "Iter 89  time=0.68  loss=281.10   feature_norm=3.22\n",
      "Iter 90  time=0.68  loss=271.78   feature_norm=3.23\n",
      "Iter 91  time=0.67  loss=284.38   feature_norm=3.24\n",
      "Iter 92  time=0.67  loss=269.26   feature_norm=3.25\n",
      "Iter 93  time=0.69  loss=279.69   feature_norm=3.26\n",
      "Iter 94  time=0.68  loss=281.26   feature_norm=3.28\n",
      "Iter 95  time=0.68  loss=285.17   feature_norm=3.29\n",
      "Iter 96  time=0.68  loss=276.45   feature_norm=3.30\n",
      "Iter 97  time=0.69  loss=273.64   feature_norm=3.31\n",
      "Iter 98  time=0.69  loss=278.23   feature_norm=3.32\n",
      "Iter 99  time=0.68  loss=280.61   feature_norm=3.33\n",
      "Iter 100 time=0.68  loss=276.74   feature_norm=3.35\n",
      "Total seconds required for training: 61.348\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 88473 (976543)\n",
      "Number of active attributes: 72742 (960019)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.156\n",
      "\n",
      "Total rows in all_preds: 262242\n",
      "Total rows in all_golds: 262242\n"
     ]
    }
   ],
   "source": [
    "# Lists to store combined predictions and gold labels\n",
    "\n",
    "all_preds = []\n",
    "all_golds = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Running pass {i}\")\n",
    "    \n",
    "    # Identify training and testing files\n",
    "    fold_files = [f for f in os.listdir(dir_path) if f.startswith('fold.')]\n",
    "    training_files = [f for f in fold_files if not f.endswith(f\"{i}\")]\n",
    "    testing_file = [f for f in fold_files if f.endswith(f\"{i}\")][0]\n",
    "    \n",
    "    print(\"training_files\", training_files)\n",
    "    print(\"testing_file\", testing_file)\n",
    "    \n",
    "    # Load training and testing data\n",
    "    X_train, y_train = load_data([os.path.join(dir_path, f) for f in training_files])\n",
    "    X_test, y_test = load_data([os.path.join(dir_path, testing_file)])\n",
    "    \n",
    "    # Train the model\n",
    "    crf = CRF(algorithm=\"pa\",c=0.1, max_iterations=100, pa_type=2, verbose=True)\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = crf.predict(X_test)\n",
    "    \n",
    "    # Save predictions and gold labels for this fold\n",
    "    all_preds.extend([label for sublist in y_pred for label in sublist])\n",
    "    all_golds.extend(y_test)\n",
    "\n",
    "# After the loop, total counts\n",
    "print(f\"Total rows in all_preds: {len(all_preds)}\")\n",
    "print(f\"Total rows in all_golds: {len(all_golds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cafe5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in all_preds: 262242\n",
      "Total rows in all_golds: 262242\n"
     ]
    }
   ],
   "source": [
    "# # After the loop, report total counts\n",
    "# print(f\"Total rows in all_preds: {len(all_preds)}\")\n",
    "# print(f\"Total rows in all_golds: {len(all_golds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b3f16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-Processing done.\n"
     ]
    }
   ],
   "source": [
    "# Save combined predictions and gold labels to files\n",
    "field = '1439_test_pa'\n",
    "\n",
    "with open(f\"{field}.pred.raw\", \"w\") as pred_file:\n",
    "    pred_file.write(\"\\n\".join(all_preds))\n",
    "\n",
    "with open(f\"{field}.gold.raw\", \"w\") as gold_file:\n",
    "    gold_file.write(\"\\n\".join(all_golds))\n",
    "\n",
    "print(\"Post-Processing done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54cb0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions from saved files\n",
    "with open(f\"{field}.pred.raw\", \"r\") as file:\n",
    "    y_pred_flat = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5db64fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold from saved files\n",
    "with open(f\"{field}.gold.raw\", \"r\") as file:\n",
    "    y_test_flat = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03dc3159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262242, 262242)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_flat), len(y_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3e98570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', 'B'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8994e064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', 'B'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8352d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B - count in predictions: 261846\n",
      "B - count in Actual: 261705\n"
     ]
    }
   ],
   "source": [
    "B_string_count_pred = y_pred_flat.count('B')\n",
    "B_string_count_gold = y_test_flat.count('B')\n",
    "\n",
    "print(\"B - count in predictions:\", B_string_count_pred)\n",
    "print(\"B - count in Actual:\", B_string_count_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dfac9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - count in predictions: 396\n",
      "1 - count in Actual: 537\n"
     ]
    }
   ],
   "source": [
    "one_string_count_pred = y_pred_flat.count('1')\n",
    "one_string_count_gold = y_test_flat.count('1')\n",
    "\n",
    "print(\"1 - count in predictions:\", one_string_count_pred)\n",
    "print(\"1 - count in Actual:\", one_string_count_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d896ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8737373715309662, Recall: 0.6443202967517313, F1: 0.741692971780551\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn = 0, 0, 0\n",
    "for gold, pred in zip(y_test_flat, y_pred_flat):\n",
    "    # Skip empty strings\n",
    "    if gold == '' or pred == '':\n",
    "        continue\n",
    "    gold = 0 if gold == 'B' else int(gold)\n",
    "    pred = 0 if pred == 'B' else int(pred)\n",
    "    \n",
    "    if gold == 1 and pred == 1:\n",
    "        tp += 1\n",
    "    elif gold != 1 and pred == 1:\n",
    "        fp += 1\n",
    "    elif gold == 1 and pred != 1:\n",
    "        fn += 1\n",
    "\n",
    "# Compute metrics\n",
    "eps = 1e-6\n",
    "precision = tp / (tp + fp + eps)\n",
    "recall = tp / (tp + fn + eps)\n",
    "f1 = 2 * (precision * recall) / (precision + recall + eps)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e05a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cb32478",
   "metadata": {},
   "source": [
    "### Loading the files from directory where gold and pred files are saved after running CLI experiment for the same topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27dc4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions from predictions.txt\n",
    "with open(f\"{dir_path}/1439_testing_CL_pa.pred.raw\", \"r\") as file:\n",
    "    y_pred_flat_1 = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92c9f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold from gold.txt\n",
    "with open(f\"{dir_path}/1439_testing_CL_pa.gold.raw\", \"r\") as file:\n",
    "    y_test_flat_1 = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3f1dfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'', '1', 'B'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred_flat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1cde3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'', '1', 'B'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test_flat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98919bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_string_count = y_test_flat_1.count('')\n",
    "empty_string_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11025b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B - count in predictions: 261712\n",
      "B - count in Actual: 261705\n"
     ]
    }
   ],
   "source": [
    "B_string_count_pred_1 = y_pred_flat_1.count('B')\n",
    "B_string_count_gold_1 = y_test_flat_1.count('B')\n",
    "\n",
    "print(\"B - count in predictions:\", B_string_count_pred_1)\n",
    "print(\"B - count in Actual:\", B_string_count_gold_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e4f5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - count in predictions: 530\n",
      "1 - count in Actual: 537\n"
     ]
    }
   ],
   "source": [
    "one_string_count_pred_1 = y_pred_flat_1.count('1')\n",
    "one_string_count_gold_1 = y_test_flat_1.count('1')\n",
    "\n",
    "print(\"1 - count in predictions:\", one_string_count_pred_1)\n",
    "print(\"1 - count in Actual:\", one_string_count_gold_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8791c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9132075454467782, Recall: 0.9013035364966414, F1: 0.9072159931666566\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn = 0, 0, 0\n",
    "for gold, pred in zip(y_test_flat_1, y_pred_flat_1):\n",
    "    # Skip empty strings\n",
    "    if gold == '' or pred == '':\n",
    "        continue\n",
    "    gold = 0 if gold == 'B' else int(gold)\n",
    "    pred = 0 if pred == 'B' else int(pred)\n",
    "    \n",
    "    if gold == 1 and pred == 1:\n",
    "        tp += 1\n",
    "    elif gold != 1 and pred == 1:\n",
    "        fp += 1\n",
    "    elif gold == 1 and pred != 1:\n",
    "        fn += 1\n",
    "\n",
    "# Compute metrics\n",
    "eps = 1e-6\n",
    "precision = tp / (tp + fp + eps)\n",
    "recall = tp / (tp + fn + eps)\n",
    "f1 = 2 * (precision * recall) / (precision + recall + eps)\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02218673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
