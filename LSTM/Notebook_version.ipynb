{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59044c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_data, preprocess_data\n",
    "from glove_loader import load_glove_embeddings\n",
    "from train import train_evaluate_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc78a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data path\n",
    "data_path = '../../core-tech/due_dilligence_data.csv'\n",
    "glove_embbeding_path = '../../core-tech/glove.840B.300d.txt'\n",
    "# Directory to save models\n",
    "model_save_dir = 'topic_models_LSTM_imbalanced'\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "\n",
    "# load data\n",
    "df = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd604ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = load_glove_embeddings(glove_embbeding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0ed36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a column word_count\n",
    "df['word_count'] = df['sentence'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8d0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics = ['1272', ' 1474 ', ' 1238 ', ' 1275 ', ' 1239 ', ' 1520 ', ' 1509 ', ' 1240 ', ' 1308 ', ' 1319 ',\n",
    "             ' 1439 ', ' 1267 ', ' 1242 ', ' 1462 ', ' 1265 ', ' 1444 ', ' 1312 ', ' 1244 ', ' 1243 ', ' 1468 ',\n",
    "             ' 1309 ', ' 1524 ', ' 1247 ', ' 1440 ', ' 1251 ', ' 1249 ', ' 1248 ', ' 1262 ', ' 1250 ', ' 1252 ',\n",
    "             ' 1245 ', ' 1512 ', ' 1498 ', ' 1601 ', ' 1443 ', ' 1086 ', ' 1551 ', ' 1253 ', ' 1320 ', ' 1304 ',\n",
    "             ' 1469 ', ' 1611 ', ' 1300 ', ' 1489 ', ' 1500 ', ' 1261 ', ' 1318 ', ' 1460 ', ' 1475 ', ' 1321 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20804c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_topics = ['1524']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93949275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524\n",
      "Preprocessing\n",
      "vocab_size: 16711\n",
      "max_length: 443\n",
      "Model Loop\n",
      "Processing data for topic id: 1524\n",
      "Model training\n",
      "2210/2210 - 730s - loss: 0.0272 - accuracy: 0.9948 - val_loss: 0.0143 - val_accuracy: 0.9968 - 730s/epoch - 330ms/step\n",
      "Model prediction\n",
      "1105/1105 [==============================] - 100s 90ms/step\n",
      "Topic: 1524\n",
      "Precision: 0.8571, Recall: 0.5126, F1-Score: 0.6415\n",
      "118\n",
      "198\n",
      "{'TP': 101, 'FP': 17, 'FN': 97, 'Recall': 0.5101010075247424, 'Precision': 0.8559321961361679, 'F1-Score': 0.6392400343297767}\n",
      "Average Metrics Across All Topics:\n",
      "Average Precision: 0.8571\n",
      "Average Recall: 0.5126\n",
      "Average F1-Score: 0.6415\n"
     ]
    }
   ],
   "source": [
    "# Convert string IDs to integers and remove extra spaces\n",
    "unique_topics = [int(topic.strip()) for topic in unique_topics]\n",
    "\n",
    "# Number of topics\n",
    "num_topics = len(unique_topics)\n",
    "\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1_score = 0\n",
    "\n",
    "# Train and evaluate models for each topic\n",
    "for topic_id in unique_topics:\n",
    "    print(topic_id)\n",
    "    data = df[df['topic_id'] == topic_id]\n",
    "\n",
    "    print(\"Preprocessing\")\n",
    "    X, df_filtered, max_length,tokenizer_obj, vocab_size  = preprocess_data(data, glove_embeddings)\n",
    "    print(\"Model Loop\")\n",
    "    precision, recall, f1_score_1 = train_evaluate_model(X, df_filtered, max_length, topic_id, model_save_dir, \n",
    "                                                       tokenizer_obj, vocab_size, glove_embeddings)\n",
    "    sum_precision += precision\n",
    "    sum_recall += recall\n",
    "    sum_f1_score += f1_score_1\n",
    "\n",
    "\n",
    "# Calculate average metrics across all topics\n",
    "avg_precision = sum_precision / num_topics\n",
    "avg_recall = sum_recall / num_topics\n",
    "avg_f1_score = sum_f1_score / num_topics\n",
    "\n",
    "print(\"Average Metrics Across All Topics:\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a77f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99a340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
