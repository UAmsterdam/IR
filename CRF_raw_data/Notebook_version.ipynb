{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84fec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_data, read_split, stratify, map_doc\n",
    "from crf_model import train_crf_model, load_crf_model, predict_with_crf\n",
    "from tokenizer import load_tokenizer\n",
    "from features import extract_features_and_labels, process_text_and_extract_features\n",
    "from evaluation import sentence_level_results, load_labels_and_create_spans, evaluate_annotations, evaluate_model_predictions\n",
    "from train import train_loop\n",
    "from test import test_loop\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4486fd",
   "metadata": {},
   "source": [
    "## Training CRF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d6edc6",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a65bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_data, model_save_dir, topic_id, fold):\n",
    "    ''' This function is training and saving CRF model for each fold.'''\n",
    "    \n",
    "    train_sentences = train_data['sentence']\n",
    "    train_labels = train_data['label']\n",
    "    \n",
    "    tokenizer = load_tokenizer('../../core-tech/custom_punkt_tokenizer.pkl')\n",
    "    print(\"Preprocessing start\")\n",
    "    \n",
    "    # Extract features and labels for each training\n",
    "    train_extracted = [process_text_and_extract_features(sentence, label, tokenizer) for sentence, label in zip(train_sentences, train_labels)]\n",
    "    \n",
    "    \n",
    "    X_train = [features for features, _ in train_extracted]\n",
    "    y_train = [labels for _, labels in train_extracted]\n",
    "\n",
    "    print(f\"Training model for topic {topic_id} for fold {fold}\")\n",
    "\n",
    "    fold_model_dir = os.path.join(model_save_dir, topic_id)\n",
    "    \n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(fold_model_dir, exist_ok=True)\n",
    "\n",
    "    # Define the full path for the model file\n",
    "    fold_model_path = os.path.join(fold_model_dir, f\"{topic_id}_crf_model_{fold}.pkl\")\n",
    "    \n",
    "    train_crf_model(X_train, y_train, fold_model_path)\n",
    "\n",
    "    print(f\"CRF model saved for topic {topic_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a5d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_unbalanced, model_save_dir, folder, fold, results_df):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    fold_model_path = os.path.join(model_save_dir, folder, f\"{folder}_crf_model_{fold}.pkl\")\n",
    "    \n",
    "    if os.path.exists(fold_model_path):\n",
    "        crf_model = load_crf_model(fold_model_path)\n",
    "\n",
    "        # Extract features and predict\n",
    "        test_sentences = test_unbalanced['sentence']\n",
    "        test_labels = test_unbalanced['label']\n",
    "        \n",
    "        tokenizer = load_tokenizer('../../core-tech/custom_punkt_tokenizer.pkl')\n",
    "\n",
    "        test_extracted = [process_text_and_extract_features(sentence, label, tokenizer) for sentence, label in zip(test_sentences, test_labels)]\n",
    "        \n",
    "        X_test = [features for features, _ in test_extracted]\n",
    "        y_test = [labels for _, labels in test_extracted]\n",
    "\n",
    "        ## Predict\n",
    "        y_pred = predict_with_crf(crf_model, X_test)\n",
    "        results_df = evaluate_model_predictions(y_test, y_pred, fold, results_df, model_save_dir, folder)\n",
    "\n",
    "    else:\n",
    "        print(f\"Model file not found: {fold_model_path}\")\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957df54",
   "metadata": {},
   "source": [
    "### Functions to load the data using predefined folds for 5 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd4184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = '../../core-tech/core/qrels/'\n",
    "tokenizer_path = '../../core-tech/custom_punkt_tokenizer.pkl'\n",
    "data_path  = '../../core-tech/due_dilligence_data.csv'\n",
    "model_save_dir = 'raw_data_exp_25_04_24'\n",
    "\n",
    "# List of folder names you want to process\n",
    "# folders_to_process = ['1272', '1474','1238', '1275', '1239', '1520', '1509', '1240', '1308', '1319', '1439', \n",
    "#                  '1267', '1242', '1462', '1265', '1444', '1312', '1244', '1243', '1468', '1309', '1524', \n",
    "#                  '1247', '1440', '1251', '1249', '1248', '1262', '1250', '1252', '1245', '1512', '1498', \n",
    "#                  '1601', '1443', '1086', '1551', '1253', '1320', '1304', '1469', '1611', '1300', '1489', \n",
    "#                  '1500', '1261', '1318', '1460', '1475', '1321']\n",
    "\n",
    "folders_to_process = [ '1524']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0d38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f096f45f",
   "metadata": {},
   "source": [
    "### Data prepration and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8659051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa368e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold: 0\n",
      "Preprocessing start\n",
      "Training model for topic 1524 for fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|â–ˆ| 341920/341920 [01:28<00:00, 3865.10it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 1886534\n",
      "Seconds required: 24.647\n",
      "\n",
      "Passive Aggressive\n",
      "type: 2\n",
      "c: 0.100000\n",
      "error_sensitive: 1\n",
      "averaging: 1\n",
      "max_iterations: 100\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=1.89  loss=16241.26 feature_norm=3.65\n",
      "Iter 2   time=1.63  loss=12468.46 feature_norm=4.75\n",
      "Iter 3   time=1.61  loss=11225.03 feature_norm=5.58\n",
      "Iter 4   time=1.65  loss=10435.33 feature_norm=6.28\n",
      "Iter 5   time=1.64  loss=9472.83  feature_norm=6.82\n",
      "Iter 6   time=1.65  loss=9353.43  feature_norm=7.31\n",
      "Iter 7   time=1.78  loss=8362.64  feature_norm=7.75\n",
      "Iter 8   time=1.78  loss=8171.97  feature_norm=8.19\n",
      "Iter 9   time=1.75  loss=7443.61  feature_norm=8.61\n",
      "Iter 10  time=1.77  loss=8024.59  feature_norm=8.95\n",
      "Iter 11  time=1.77  loss=7497.34  feature_norm=9.27\n",
      "Iter 12  time=1.74  loss=7242.60  feature_norm=9.55\n",
      "Iter 13  time=1.73  loss=6906.92  feature_norm=9.84\n",
      "Iter 14  time=1.73  loss=7027.59  feature_norm=10.11\n",
      "Iter 15  time=1.75  loss=6385.99  feature_norm=10.37\n",
      "Iter 16  time=1.72  loss=6580.79  feature_norm=10.63\n",
      "Iter 17  time=1.66  loss=6440.20  feature_norm=10.85\n",
      "Iter 18  time=1.66  loss=6063.50  feature_norm=11.10\n",
      "Iter 19  time=1.64  loss=5698.90  feature_norm=11.30\n",
      "Iter 20  time=1.64  loss=5822.57  feature_norm=11.53\n",
      "Iter 21  time=1.65  loss=5874.66  feature_norm=11.74\n",
      "Iter 22  time=1.65  loss=5927.31  feature_norm=11.93\n",
      "Iter 23  time=1.67  loss=5471.28  feature_norm=12.12\n",
      "Iter 24  time=1.64  loss=5633.76  feature_norm=12.34\n",
      "Iter 25  time=2.16  loss=5568.92  feature_norm=12.53\n",
      "Iter 26  time=2.33  loss=5482.21  feature_norm=12.70\n",
      "Iter 27  time=1.84  loss=5212.61  feature_norm=12.87\n",
      "Iter 28  time=1.72  loss=4863.97  feature_norm=13.02\n",
      "Iter 29  time=1.68  loss=4989.73  feature_norm=13.17\n",
      "Iter 30  time=1.71  loss=5033.04  feature_norm=13.32\n",
      "Iter 31  time=1.68  loss=4998.00  feature_norm=13.47\n",
      "Iter 32  time=1.67  loss=4522.63  feature_norm=13.62\n",
      "Iter 33  time=1.71  loss=4838.53  feature_norm=13.77\n",
      "Iter 34  time=1.67  loss=4923.28  feature_norm=13.91\n",
      "Iter 35  time=1.74  loss=4642.35  feature_norm=14.05\n",
      "Iter 36  time=1.67  loss=4502.23  feature_norm=14.19\n",
      "Iter 37  time=1.64  loss=4758.22  feature_norm=14.34\n",
      "Iter 38  time=1.67  loss=4552.45  feature_norm=14.48\n",
      "Iter 39  time=1.62  loss=4664.71  feature_norm=14.63\n",
      "Iter 40  time=1.66  loss=4484.39  feature_norm=14.77\n",
      "Iter 41  time=1.83  loss=4317.80  feature_norm=14.89\n",
      "Iter 42  time=1.71  loss=3972.19  feature_norm=15.01\n",
      "Iter 43  time=1.70  loss=4340.91  feature_norm=15.12\n",
      "Iter 44  time=1.75  loss=4242.06  feature_norm=15.25\n",
      "Iter 45  time=1.76  loss=4281.74  feature_norm=15.37\n",
      "Iter 46  time=1.75  loss=4474.78  feature_norm=15.50\n",
      "Iter 47  time=1.70  loss=3888.18  feature_norm=15.60\n",
      "Iter 48  time=1.70  loss=4126.06  feature_norm=15.73\n",
      "Iter 49  time=1.72  loss=4125.51  feature_norm=15.85\n",
      "Iter 50  time=1.72  loss=3922.64  feature_norm=15.95\n",
      "Iter 51  time=1.76  loss=3943.87  feature_norm=16.04\n",
      "Iter 52  time=1.69  loss=3832.58  feature_norm=16.14\n",
      "Iter 53  time=1.68  loss=3384.79  feature_norm=16.25\n",
      "Iter 54  time=1.72  loss=4003.49  feature_norm=16.36\n",
      "Iter 55  time=1.68  loss=3769.43  feature_norm=16.47\n",
      "Iter 56  time=1.59  loss=3711.59  feature_norm=16.57\n",
      "Iter 57  time=1.59  loss=3590.60  feature_norm=16.67\n",
      "Iter 58  time=1.59  loss=3831.64  feature_norm=16.76\n",
      "Iter 59  time=1.60  loss=4080.51  feature_norm=16.87\n",
      "Iter 60  time=1.61  loss=3505.67  feature_norm=16.96\n",
      "Iter 61  time=1.61  loss=3499.39  feature_norm=17.07\n",
      "Iter 62  time=1.60  loss=3607.93  feature_norm=17.17\n",
      "Iter 63  time=1.59  loss=3603.72  feature_norm=17.26\n",
      "Iter 64  time=1.59  loss=3444.24  feature_norm=17.35\n",
      "Iter 65  time=1.59  loss=3399.89  feature_norm=17.45\n",
      "Iter 66  time=1.59  loss=3671.73  feature_norm=17.54\n",
      "Iter 67  time=1.66  loss=3286.52  feature_norm=17.62\n",
      "Iter 68  time=1.64  loss=3560.75  feature_norm=17.71\n",
      "Iter 69  time=1.66  loss=3386.05  feature_norm=17.80\n",
      "Iter 70  time=1.61  loss=3408.81  feature_norm=17.89\n",
      "Iter 71  time=1.62  loss=3377.51  feature_norm=17.99\n",
      "Iter 72  time=1.60  loss=3129.78  feature_norm=18.07\n",
      "Iter 73  time=1.64  loss=3549.95  feature_norm=18.13\n",
      "Iter 74  time=1.59  loss=3381.01  feature_norm=18.22\n",
      "Iter 75  time=1.60  loss=3171.20  feature_norm=18.30\n",
      "Iter 76  time=1.59  loss=3127.61  feature_norm=18.37\n",
      "Iter 77  time=1.60  loss=3323.01  feature_norm=18.46\n",
      "Iter 78  time=1.59  loss=3491.14  feature_norm=18.54\n",
      "Iter 79  time=1.59  loss=3530.50  feature_norm=18.62\n",
      "Iter 80  time=1.60  loss=3122.74  feature_norm=18.69\n",
      "Iter 81  time=1.59  loss=3069.27  feature_norm=18.76\n",
      "Iter 82  time=1.67  loss=3356.31  feature_norm=18.83\n",
      "Iter 83  time=1.59  loss=2899.97  feature_norm=18.90\n",
      "Iter 84  time=1.59  loss=3362.69  feature_norm=18.98\n",
      "Iter 85  time=1.62  loss=3106.12  feature_norm=19.03\n",
      "Iter 86  time=1.63  loss=3103.83  feature_norm=19.11\n",
      "Iter 87  time=1.60  loss=2949.49  feature_norm=19.20\n",
      "Iter 88  time=1.59  loss=2893.71  feature_norm=19.26\n",
      "Iter 89  time=1.61  loss=2931.96  feature_norm=19.33\n",
      "Iter 90  time=1.60  loss=3073.06  feature_norm=19.40\n",
      "Iter 91  time=1.59  loss=2854.62  feature_norm=19.46\n",
      "Iter 92  time=1.59  loss=3383.95  feature_norm=19.53\n",
      "Iter 93  time=1.59  loss=2950.63  feature_norm=19.59\n",
      "Iter 94  time=1.59  loss=2898.91  feature_norm=19.66\n",
      "Iter 95  time=1.59  loss=3015.64  feature_norm=19.72\n",
      "Iter 96  time=1.59  loss=2931.07  feature_norm=19.79\n",
      "Iter 97  time=1.58  loss=2823.25  feature_norm=19.86\n",
      "Iter 98  time=1.59  loss=3183.51  feature_norm=19.93\n",
      "Iter 99  time=1.59  loss=3108.71  feature_norm=20.01\n",
      "Iter 100 time=1.69  loss=3193.61  feature_norm=20.08\n",
      "Total seconds required for training: 167.027\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 261527 (1886534)\n",
      "Number of active attributes: 235772 (1860769)\n",
      "Number of active labels: 2 (2)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.745\n",
      "\n",
      "CRF model saved for topic 1524\n",
      "Precision: 0.925777599662825, Recall: 0.6921157683940004, F1: 0.7920730641051152\n",
      "Avg Precision: 0.9258, Avg Recall: 0.6921, Avg F1-Score: 0.7921\n",
      "47\n",
      "101\n",
      "{'TP': 86, 'FP': 6, 'FN': 15, 'Precision': 0.9347825985349718, 'Recall': 0.8514851400843055, 'F1-Score': 0.8911912016969693}\n",
      "\n",
      " Completed all folds\n",
      "Results saved to raw_data_exp_25_04_24/1524/final_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over folders\n",
    "for folder in folders_to_process:\n",
    "    \n",
    "    ## Dataframe to store the results\n",
    "    results_df = pd.DataFrame(columns=[\"Topic ID\", \"Fold\", \"Sentence Precision\", \"Sentence Recall\", \"Sentence F1-Score\",\n",
    "                               \"Annotation TP\", \"Annotation FP\", \"Annotation FN\", \n",
    "                               \"Annotation Precision\", \"Annotation Recall\", \"Annotation F1-Score\"])\n",
    "\n",
    "\n",
    "    if folder in os.listdir(path):\n",
    "        for fold in range(1):\n",
    "            \n",
    "            ####### Data split into train and test sets #######\n",
    "            print(\"For fold:\", fold)\n",
    "            test_split = fold\n",
    "            train_split = [i for i in range(5) if i != test_split]\n",
    "            \n",
    "            test = read_split(f'{path}/{folder}/{folder}-{test_split}.cache')\n",
    "            train = sum([read_split(f'{path}/{folder}/{folder}-{el}.cache') for el in train_split], [])\n",
    "\n",
    "            df_ = df[df['topic_id'] == int(folder)].dropna()\n",
    "#             df_ = df_.dropna()\n",
    "            df_['doc_id'] = df_.apply(map_doc, axis=1)\n",
    "\n",
    "            df_train = df_[df_['doc_id'].isin(train)]\n",
    "            df_test = df_[df_['doc_id'].isin(test)]\n",
    "                    \n",
    "            ## genertae test data\n",
    "            test_unbalanced, test_balanced = stratify(df_test)\n",
    "            train_unbalanced, train_balanced = stratify(df_train)\n",
    "            \n",
    "            ######### Model training ##############\n",
    "\n",
    "            os.makedirs(model_save_dir, exist_ok=True)\n",
    "            \n",
    "            ## train CRF model\n",
    "            train_loop(train_unbalanced, model_save_dir, str(int(folder)), fold, tokenizer)\n",
    "            \n",
    "            ## test CRF model\n",
    "            results_df = test_loop(test_unbalanced, model_save_dir, folder, fold, results_df, tokenizer)\n",
    "    \n",
    "    \n",
    "    print(\"\\n Completed all folds\")\n",
    "    # Save results to CSV\n",
    "    results_csv_path = os.path.join(model_save_dir, folder, \"final_results.csv\")\n",
    "    results_df.to_csv(results_csv_path, index=False)\n",
    "    print(f\"Results saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336f8fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic ID</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Sentence Precision</th>\n",
       "      <th>Sentence Recall</th>\n",
       "      <th>Sentence F1-Score</th>\n",
       "      <th>Annotation TP</th>\n",
       "      <th>Annotation FP</th>\n",
       "      <th>Annotation FN</th>\n",
       "      <th>Annotation Precision</th>\n",
       "      <th>Annotation Recall</th>\n",
       "      <th>Annotation F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925778</td>\n",
       "      <td>0.692116</td>\n",
       "      <td>0.792073</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.891191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic ID Fold  Sentence Precision  Sentence Recall  Sentence F1-Score  \\\n",
       "0     1524    0            0.925778         0.692116           0.792073   \n",
       "\n",
       "  Annotation TP Annotation FP Annotation FN  Annotation Precision  \\\n",
       "0            86             6            15              0.934783   \n",
       "\n",
       "   Annotation Recall  Annotation F1-Score  \n",
       "0           0.851485             0.891191  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f8a13",
   "metadata": {},
   "source": [
    "### Calculating mean across topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ea7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "# Step 1: Loop through each topic ID and read the CSV file\n",
    "for topic_id in folders_to_process:\n",
    "    csv_path = os.path.join('./',str(topic_id), \"final_results.csv\")\n",
    "    print(csv_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Step 2: Concatenate all DataFrames\n",
    "combined_df = pd.concat(dataframes)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean for each topic across all folds\n",
    "topic_means = combined_df.groupby('Topic ID').mean().drop(columns='Fold')\n",
    "\n",
    "# Calculate the mean of means across all topics\n",
    "overall_means = topic_means.mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Mean Metrics for Each Topic:\")\n",
    "print(topic_means)\n",
    "print(\"\\nOverall Mean Metrics Across All Topics:\")\n",
    "print(overall_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7912850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be8f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
